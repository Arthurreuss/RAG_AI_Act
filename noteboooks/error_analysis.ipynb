{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e6fc59",
   "metadata": {},
   "source": [
    "\n",
    "# Error Analysis\n",
    "\n",
    "\n",
    "#### **1. Retrieval Precision: Hits vs. Near Misses**\n",
    "\n",
    "In a legal context, a retrieval \"fail\" often simply means the exact paragraph was missed, while the correct article or section was still found.\n",
    "\n",
    "* **Single-Turn Resilience:** **61.1%** of retrieval misses were \"Near Misses,\" where the system found the correct article/recital/annex but the wrong specific paragraph or subpoint.\n",
    "* **Reranking Impact:** Reranking significantly tightens precision. In multi-turn scenarios, **83.6%** of misses were \"Near Misses,\" ensuring the model almost always had the correct article even if it missed the specific paragraph.\n",
    "\n",
    "#### **2. RAG Behavior Categories**\n",
    "\n",
    "We categorize the system's output into four types to understand its failure modes:\n",
    "\n",
    "* **Success (Retrieval + Good Answer):** The target state. This occurs in over **90%** of single-turn queries.\n",
    "* **Lucky Guess (Retrieval Missed + Good Answer):** The model uses its internal knowledge and  closely related context to answer correctly despite missing the specific text. This is common in multi-turn dialogues (**14%**).\n",
    "* **System Failure (Retrieval Missed + Poor Answer):** The model lacks the specific legal knowledge to answer without the correct text.\n",
    "* **Context Ignored (Retrieval + Poor Answer):** A rare event (**<5%**) where the model has the right text but fails to use it, indicating high model \"faithfulness\" to the provided law.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16347b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.analysis.analyze_errors import ErrorAnalyzer\n",
    "\n",
    "project_root = Path.cwd().parent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df1cfcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Turn\n",
      "Loaded 747 records for analysis.\n",
      "\n",
      "RETRIEVAL: Exact Hits vs. Near Misses\n",
      "----------------------------------------\n",
      "Total Retrieval Misses: 54\n",
      "Near Misses (Correct Doc, Wrong Chunk): 33\n",
      "-> 61.1% of misses were actually close!\n",
      "\n",
      "RAG BEHAVIOR CATEGORIES\n",
      "----------------------------------------\n",
      "Success (Retrieval + Good Answer): 675 (90.4%)\n",
      "Lucky Guess (Rretrieval missed + Good Answer): 29 (3.9%)\n",
      "System Failure (Retrieval missed + Poor Answer): 25 (3.3%)\n",
      "Context Ignored (Retrieval + Poor Answer): 18 (2.4%)\n",
      "\n",
      "Single Turn Reranked\n",
      "Loaded 747 records for analysis.\n",
      "\n",
      "RETRIEVAL: Exact Hits vs. Near Misses\n",
      "----------------------------------------\n",
      "Total Retrieval Misses: 27\n",
      "Near Misses (Correct Doc, Wrong Chunk): 18\n",
      "-> 66.7% of misses were actually close!\n",
      "\n",
      "RAG BEHAVIOR CATEGORIES\n",
      "----------------------------------------\n",
      "Success (Retrieval + Good Answer): 701 (93.8%)\n",
      "Context Ignored (Retrieval + Poor Answer): 19 (2.5%)\n",
      "Lucky Guess (Rretrieval missed + Good Answer): 18 (2.4%)\n",
      "System Failure (Retrieval missed + Poor Answer): 9 (1.2%)\n",
      "\n",
      "Multi-Turn Performance Decay\n",
      "----------------------------------------\n",
      "            rag_score hit_rate baseline_score\n",
      "turn_number                                  \n",
      "1                8.39    96.4%           5.38\n",
      "\n",
      "Context Dependency Check:\n",
      "Turn 1: RAG beat Baseline in 542/747 cases\n"
     ]
    }
   ],
   "source": [
    "print(\"Single Turn\")\n",
    "file_path = project_root / \"results/rag_eval_full_single_queries_20260112_200932.json\" \n",
    "\n",
    "analyzer = ErrorAnalyzer(file_path)\n",
    "\n",
    "analyzer.check_near_misses()\n",
    "analyzer.categorize_failures()\n",
    "analyzer.analyze_multi_turn_decay()\n",
    "\n",
    "print(\"\\nSingle Turn Reranked\")\n",
    "file_path = project_root / \"results/rag_eval_full_single_turn_reranked_20260113_020921.json\" \n",
    "\n",
    "analyzer = ErrorAnalyzer(file_path)\n",
    "\n",
    "analyzer.check_near_misses()\n",
    "analyzer.categorize_failures()\n",
    "analyzer.analyze_multi_turn_decay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "568b3572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Turn\n",
      "Loaded 228 records for analysis.\n",
      "\n",
      "RETRIEVAL: Exact Hits vs. Near Misses\n",
      "----------------------------------------\n",
      "Total Retrieval Misses: 55\n",
      "Near Misses (Correct Doc, Wrong Chunk): 33\n",
      "-> 60.0% of misses were actually close!\n",
      "\n",
      "RAG BEHAVIOR CATEGORIES\n",
      "----------------------------------------\n",
      "Success (Retrieval + Good Answer): 165 (72.4%)\n",
      "System Failure (Retrieval missed + Poor Answer): 30 (13.2%)\n",
      "Lucky Guess (Rretrieval missed + Good Answer): 25 (11.0%)\n",
      "Context Ignored (Retrieval + Poor Answer): 8 (3.5%)\n",
      "\n",
      "Multi-Turn Performance Decay\n",
      "----------------------------------------\n",
      "            rag_score hit_rate baseline_score\n",
      "turn_number                                  \n",
      "1                8.13    84.5%           5.42\n",
      "2                7.52    77.5%           7.23\n",
      "3                6.64    65.2%           7.13\n",
      "4                7.24    76.5%           7.00\n",
      "\n",
      "Context Dependency Check:\n",
      "Turn 1: RAG beat Baseline in 49/71 cases\n",
      "Turn 2: RAG beat Baseline in 28/71 cases\n",
      "Turn 3: RAG beat Baseline in 28/69 cases\n",
      "Turn 4: RAG beat Baseline in 6/17 cases\n",
      "\n",
      "Multi Turn Reranked\n",
      "Loaded 228 records for analysis.\n",
      "\n",
      "RETRIEVAL: Exact Hits vs. Near Misses\n",
      "----------------------------------------\n",
      "Total Retrieval Misses: 47\n",
      "Near Misses (Correct Doc, Wrong Chunk): 38\n",
      "-> 80.9% of misses were actually close!\n",
      "\n",
      "RAG BEHAVIOR CATEGORIES\n",
      "----------------------------------------\n",
      "Success (Retrieval + Good Answer): 170 (74.6%)\n",
      "Lucky Guess (Rretrieval missed + Good Answer): 24 (10.5%)\n",
      "System Failure (Retrieval missed + Poor Answer): 23 (10.1%)\n",
      "Context Ignored (Retrieval + Poor Answer): 11 (4.8%)\n",
      "\n",
      "Multi-Turn Performance Decay\n",
      "----------------------------------------\n",
      "            rag_score hit_rate baseline_score\n",
      "turn_number                                  \n",
      "1                8.39    88.7%           5.08\n",
      "2                7.27    78.9%           7.11\n",
      "3                7.10    69.6%           7.06\n",
      "4                7.94    82.4%           6.59\n",
      "\n",
      "Context Dependency Check:\n",
      "Turn 1: RAG beat Baseline in 55/71 cases\n",
      "Turn 2: RAG beat Baseline in 27/71 cases\n",
      "Turn 3: RAG beat Baseline in 28/69 cases\n",
      "Turn 4: RAG beat Baseline in 9/17 cases\n"
     ]
    }
   ],
   "source": [
    "print(\"Multi Turn\")\n",
    "file_path = project_root / \"results/rag_eval_full_multi_turn_20260114_215828.json\" \n",
    "\n",
    "analyzer = ErrorAnalyzer(file_path)\n",
    "\n",
    "analyzer.check_near_misses()\n",
    "analyzer.categorize_failures()\n",
    "analyzer.analyze_multi_turn_decay()\n",
    "\n",
    "print(\"\\nMulti Turn Reranked\")\n",
    "file_path = project_root / \"results/rag_eval_full_multi_turn_reranked_20260114_202740.json\" \n",
    "\n",
    "analyzer = ErrorAnalyzer(file_path)\n",
    "\n",
    "analyzer.check_near_misses()\n",
    "analyzer.categorize_failures()\n",
    "analyzer.analyze_multi_turn_decay()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-ai-act",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
